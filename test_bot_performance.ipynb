{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miyamura80/BotsForGames/blob/main/BotsForGames_Sprint2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0DCN2-Op6F2",
        "outputId": "84d856f6-558c-486b-db11-f7c207ba81cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\eito miyamura\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (1.11.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\eito miyamura\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from torch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "# environment:\n",
        "!pip3 install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycSlk7q8p6F4",
        "outputId": "0a55f17e-96c6-4f91-8d33-b63b23cb6efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1 2 3\n",
            "A _ _ _\n",
            "B O _ _\n",
            "C _ _ _\n",
            "record = B1\n",
            "input feature\n",
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [1. 0. 0.]\n",
            "  [0. 0. 0.]]]\n",
            "input feature\n",
            "[[[1. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 1. 0.]\n",
            "  [0. 1. 0.]]]\n"
          ]
        }
      ],
      "source": [
        "# Implementation of simple game: Tic-Tac-Toe\n",
        "# You can change this to another two-player game.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "BLACK, WHITE = 1, -1  # first turn or second turn player\n",
        "\n",
        "class State:\n",
        "    '''Board implementation of Tic-Tac-Toe'''\n",
        "    X, Y = 'ABC',  '123'\n",
        "    C = {0: '_', BLACK: 'O', WHITE: 'X'}\n",
        "\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3, 3)) # (x, y)\n",
        "        self.color = 1\n",
        "        self.win_color = 0\n",
        "        self.record = []\n",
        "\n",
        "    def action2str(self, a):\n",
        "        return self.X[a // 3] + self.Y[a % 3]\n",
        "\n",
        "    def str2action(self, s):\n",
        "        return self.X.find(s[0]) * 3 + self.Y.find(s[1])\n",
        "\n",
        "    def record_string(self):\n",
        "        return ' '.join([self.action2str(a) for a in self.record])\n",
        "\n",
        "    def __str__(self):\n",
        "        # output board.\n",
        "        s = '   ' + ' '.join(self.Y) + '\\n'\n",
        "        for i in range(3):\n",
        "            s += self.X[i] + ' ' + ' '.join([self.C[self.board[i, j]] for j in range(3)]) + '\\n'\n",
        "        s += 'record = ' + self.record_string()\n",
        "        return s\n",
        "\n",
        "    def play(self, action):\n",
        "        # state transition function\n",
        "        # action is position inerger (0~8) or string representation of action sequence\n",
        "        if isinstance(action, str):\n",
        "            for astr in action.split():\n",
        "                self.play(self.str2action(astr))\n",
        "            return self\n",
        "\n",
        "        x, y = action // 3, action % 3\n",
        "        self.board[x, y] = self.color\n",
        "\n",
        "        # check whether 3 stones are on the line\n",
        "        if self.board[x, :].sum() == 3 * self.color \\\n",
        "          or self.board[:, y].sum() == 3 * self.color \\\n",
        "          or (x == y and np.diag(self.board, k=0).sum() == 3 * self.color) \\\n",
        "          or (x == 2 - y and np.diag(self.board[::-1,:], k=0).sum() == 3 * self.color):\n",
        "            self.win_color = self.color\n",
        "\n",
        "        self.color = -self.color\n",
        "        self.record.append(action)\n",
        "        return self\n",
        "\n",
        "    def terminal(self):\n",
        "        # terminal state check\n",
        "        return self.win_color != 0 or len(self.record) == 3 * 3\n",
        "\n",
        "    def terminal_reward(self):\n",
        "        # terminal reward \n",
        "        return self.win_color if self.color == BLACK else -self.win_color\n",
        "\n",
        "    def legal_actions(self):\n",
        "        # list of legal actions on each state\n",
        "        return [a for a in range(3 * 3) if self.board[a // 3, a % 3] == 0]\n",
        "\n",
        "    def feature(self):\n",
        "        # input tensor for neural net (state)\n",
        "        return np.stack([self.board == self.color, self.board == -self.color]).astype(np.float32)\n",
        "\n",
        "    def action_feature(self, action):\n",
        "        # input tensor for neural net (action)\n",
        "        a = np.zeros((1, 3, 3), dtype=np.float32)\n",
        "        a[0, action // 3, action % 3] = 1\n",
        "        return a\n",
        "\n",
        "state = State().play('B1')\n",
        "print(state)\n",
        "print('input feature')\n",
        "print(state.feature())\n",
        "state = State().play('B2 A1 C2')\n",
        "print('input feature')\n",
        "print(state.feature())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M4TlYnoxp6GA"
      },
      "outputs": [],
      "source": [
        "# Small neural nets with PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self, filters0, filters1, kernel_size, bn=False):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(filters0, filters1, kernel_size, stride=1, padding=kernel_size//2, bias=False)\n",
        "        self.bn = None\n",
        "        if bn:\n",
        "            self.bn = nn.BatchNorm2d(filters1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv(x)\n",
        "        if self.bn is not None:\n",
        "            h = self.bn(h)\n",
        "        return h\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, filters):\n",
        "        super().__init__()\n",
        "        self.conv = Conv(filters, filters, 3, True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(x + (self.conv(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KUYX23urp6GC"
      },
      "outputs": [],
      "source": [
        "num_filters = 16\n",
        "num_blocks = 4\n",
        "\n",
        "class Representation(nn.Module):\n",
        "    ''' Conversion from observation to inner abstract state '''\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.board_size = self.input_shape[1] * self.input_shape[2]\n",
        "\n",
        "        self.layer0 = Conv(self.input_shape[0], num_filters, 3, bn=True)\n",
        "        self.blocks = nn.ModuleList([ResidualBlock(num_filters) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.layer0(x))\n",
        "        for block in self.blocks:\n",
        "            h = block(h)\n",
        "        return h\n",
        "\n",
        "    def inference(self, x):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            rp = self(torch.from_numpy(x).unsqueeze(0))\n",
        "        return rp.cpu().numpy()[0]\n",
        "\n",
        "class Prediction(nn.Module):\n",
        "    ''' Policy and value prediction from inner abstract state '''\n",
        "    def __init__(self, action_shape):\n",
        "        super().__init__()\n",
        "        self.board_size = np.prod(action_shape[1:])\n",
        "        self.action_size = action_shape[0] * self.board_size\n",
        "\n",
        "        self.conv_p1 = Conv(num_filters, 4, 1, bn=True)\n",
        "        self.conv_p2 = Conv(4, 1, 1)\n",
        "\n",
        "        self.conv_v = Conv(num_filters, 4, 1, bn=True)\n",
        "        self.fc_v = nn.Linear(self.board_size * 4, 1, bias=False)\n",
        "\n",
        "    def forward(self, rp):\n",
        "        h_p = F.relu(self.conv_p1(rp))\n",
        "        h_p = self.conv_p2(h_p).view(-1, self.action_size)\n",
        "\n",
        "        h_v = F.relu(self.conv_v(rp))\n",
        "        h_v = self.fc_v(h_v.view(-1, self.board_size * 4))\n",
        "\n",
        "        # range of value is -1 ~ 1\n",
        "        return F.softmax(h_p, dim=-1), torch.tanh(h_v)\n",
        "\n",
        "    def inference(self, rp):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            p, v = self(torch.from_numpy(rp).unsqueeze(0))\n",
        "        return p.cpu().numpy()[0], v.cpu().numpy()[0][0]\n",
        "\n",
        "class Dynamics(nn.Module):\n",
        "    '''Abstract state transition'''\n",
        "    def __init__(self, rp_shape, act_shape):\n",
        "        super().__init__()\n",
        "        self.rp_shape = rp_shape\n",
        "        self.layer0 = Conv(rp_shape[0] + act_shape[0], num_filters, 3, bn=True)\n",
        "        self.blocks = nn.ModuleList([ResidualBlock(num_filters) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, rp, a):\n",
        "        h = torch.cat([rp, a], dim=1)\n",
        "        h = self.layer0(h)\n",
        "        for block in self.blocks:\n",
        "            h = block(h)\n",
        "        return h\n",
        "\n",
        "    def inference(self, rp, a):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            rp = self(torch.from_numpy(rp).unsqueeze(0), torch.from_numpy(a).unsqueeze(0))\n",
        "        return rp.cpu().numpy()[0]\n",
        "\n",
        "class Net(nn.Module):\n",
        "    '''Whole net'''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        state = State()\n",
        "        input_shape = state.feature().shape\n",
        "        action_shape = state.action_feature(0).shape\n",
        "        rp_shape = (num_filters, *input_shape[1:])\n",
        "\n",
        "        self.representation = Representation(input_shape)\n",
        "        self.prediction = Prediction(action_shape)\n",
        "        self.dynamics = Dynamics(rp_shape, action_shape)\n",
        "\n",
        "    def predict(self, state0, path):\n",
        "        '''Predict p and v from original state and path'''\n",
        "        outputs = []\n",
        "        x = state0.feature()\n",
        "        rp = self.representation.inference(x)\n",
        "        outputs.append(self.prediction.inference(rp))\n",
        "        for action in path:\n",
        "            a = state0.action_feature(action)\n",
        "            rp = self.dynamics.inference(rp, a)\n",
        "            outputs.append(self.prediction.inference(rp))\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Nq-MFjop6GE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1 2 3\n",
            "A _ _ _\n",
            "B _ _ _\n",
            "C _ _ _\n",
            "record = \n",
            "p = \n",
            "[[[111 111 111]\n",
            "  [111 111 111]\n",
            "  [111 111 111]]]\n",
            "v =  0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def show_net(net, state):\n",
        "    '''Display policy (p) and value (v)'''\n",
        "    print(state)\n",
        "    p, v = net.predict(state, [])[-1]\n",
        "    print('p = ')\n",
        "    print((p * 1000).astype(int).reshape((-1, *net.representation.input_shape[1:3])))\n",
        "    print('v = ', v)\n",
        "    print()\n",
        "\n",
        "#  Outputs before training\n",
        "show_net(Net(), State())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rqlkZ8MCp6GE"
      },
      "outputs": [],
      "source": [
        "# Implementation of Monte Carlo Tree Search\n",
        "\n",
        "class Node:\n",
        "    '''Search result of one abstract (or root) state'''\n",
        "    def __init__(self, p, v):\n",
        "        self.p, self.v = p, v\n",
        "        self.n, self.q_sum = np.zeros_like(p), np.zeros_like(p)\n",
        "        self.n_all, self.q_sum_all = 1, v / 2 # prior\n",
        "\n",
        "    def update(self, action, q_new):\n",
        "        # Update\n",
        "        self.n[action] += 1\n",
        "        self.q_sum[action] += q_new\n",
        "\n",
        "        # Update overall stats\n",
        "        self.n_all += 1\n",
        "        self.q_sum_all += q_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nMuA1Ednp6GF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "class Tree:\n",
        "    '''Monte Carlo Tree'''\n",
        "    def __init__(self, net):\n",
        "        self.net = net\n",
        "        self.nodes = {}\n",
        "\n",
        "    def search(self, state, path, rp, depth):\n",
        "        # Return predicted value from new state\n",
        "        key = state.record_string()\n",
        "        if len(path) > 0:\n",
        "            key += '|' + ' '.join(map(state.action2str, path))\n",
        "        if key not in self.nodes:\n",
        "            p, v = self.net.prediction.inference(rp)\n",
        "            self.nodes[key] = Node(p, v)\n",
        "            return v\n",
        "\n",
        "        # State transition by an action selected from bandit\n",
        "        node = self.nodes[key]\n",
        "        p = node.p\n",
        "        mask = np.zeros_like(p)\n",
        "        if depth == 0:\n",
        "            # Add noise to policy on the root node\n",
        "            p = 0.75 * p + 0.25 * np.random.dirichlet([0.15] * len(p))\n",
        "            # On the root node, we choose action only from legal actions\n",
        "            mask[state.legal_actions()] = 1\n",
        "            p *= mask\n",
        "            p /= p.sum() + 1e-16\n",
        "\n",
        "        n, q_sum = 1 + node.n, node.q_sum_all / node.n_all + node.q_sum\n",
        "        ucb = q_sum / n + 2.0 * np.sqrt(node.n_all) * p / n + mask * 4 # PUCB formula\n",
        "        best_action = np.argmax(ucb)\n",
        "\n",
        "        # Search next state by recursively calling this function\n",
        "        rp_next = self.net.dynamics.inference(rp, state.action_feature(best_action))\n",
        "        path.append(best_action)\n",
        "        q_new = -self.search(state, path, rp_next, depth + 1) # With the assumption of changing player by turn\n",
        "        node.update(best_action, q_new)\n",
        "\n",
        "        return q_new\n",
        "\n",
        "    def think(self, state, num_simulations, temperature = 0, show=False):\n",
        "        # End point of MCTS\n",
        "        if show:\n",
        "            print(state)\n",
        "        start, prev_time = time.time(), 0\n",
        "        for _ in range(num_simulations):\n",
        "            self.search(state, [], self.net.representation.inference(state.feature()), depth=0)\n",
        "\n",
        "            # Display search result on every second\n",
        "            if show:\n",
        "                tmp_time = time.time() - start\n",
        "                if int(tmp_time) > int(prev_time):\n",
        "                    prev_time = tmp_time\n",
        "                    root, pv = self.nodes[state.record_string()], self.pv(state)\n",
        "                    print('%.2f sec. best %s. q = %.4f. n = %d / %d. pv = %s'\n",
        "                          % (tmp_time, state.action2str(pv[0]), root.q_sum[pv[0]] / root.n[pv[0]],\n",
        "                             root.n[pv[0]], root.n_all, ' '.join([state.action2str(a) for a in pv])))\n",
        "\n",
        "        #  Return probability distribution weighted by the number of simulations\n",
        "        root = self.nodes[state.record_string()]\n",
        "        n = root.n + 1\n",
        "        n = (n / np.max(n)) ** (1 / (temperature + 1e-8))\n",
        "        return n / n.sum()\n",
        "\n",
        "    def pv(self, state):\n",
        "        # Return principal variation (action sequence which is considered as the best)\n",
        "        s, pv_seq = copy.deepcopy(state), []\n",
        "        while True:\n",
        "            key = s.record_string()\n",
        "            if key not in self.nodes or self.nodes[key].n.sum() == 0:\n",
        "                break\n",
        "            best_action = sorted([(a, self.nodes[key].n[a]) for a in s.legal_actions()], key=lambda x: -x[1])[0][0]\n",
        "            pv_seq.append(best_action)\n",
        "            s.play(best_action)\n",
        "        return pv_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SGrCluKrp6GG",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Eito Miyamura\\Documents\\Github\\BotsForGames\\test_bot_performance.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eito%20Miyamura/Documents/Github/BotsForGames/test_bot_performance.ipynb#ch0000008?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Net()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eito%20Miyamura/Documents/Github/BotsForGames/test_bot_performance.ipynb#ch0000008?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mnetwork.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eito%20Miyamura/Documents/Github/BotsForGames/test_bot_performance.ipynb#ch0000008?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=709'>710</a>\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=710'>711</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=711'>712</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=712'>713</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:1046\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1043'>1044</a>\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1044'>1045</a>\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1045'>1046</a>\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1047'>1048</a>\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1049'>1050</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:1016\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1013'>1014</a>\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1014'>1015</a>\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1015'>1016</a>\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1017'>1018</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=996'>997</a>\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39m_UntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_untyped()\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=997'>998</a>\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=998'>999</a>\u001b[0m \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=999'>1000</a>\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[1;32m-> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1000'>1001</a>\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=1001'>1002</a>\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=173'>174</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=174'>175</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=175'>176</a>\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=176'>177</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=177'>178</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=149'>150</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=150'>151</a>\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=151'>152</a>\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=152'>153</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=153'>154</a>\u001b[0m             storage_type \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch\u001b[39m.\u001b[39mcuda, \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=132'>133</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=134'>135</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m--> <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=135'>136</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=136'>137</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=137'>138</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=138'>139</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=139'>140</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=140'>141</a>\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/Eito%20Miyamura/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/serialization.py?line=141'>142</a>\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "model = Net()\n",
        "model.load_state_dict(torch.load('network.pkl'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGJtw40qp6GH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRo8A-WTp6GI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviavCidp6GJ",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d1b4IrSp6GJ"
      },
      "outputs": [],
      "source": [
        "# Show outputs from trained net\n",
        "\n",
        "print('initial state')\n",
        "show_net(net, State())\n",
        "\n",
        "print('WIN by put')\n",
        "show_net(net, State().play('A1 C1 A2 C2'))\n",
        "\n",
        "print('LOSE by opponent\\'s double')\n",
        "show_net(net, State().play('B2 A2 A3 C1 B3'))\n",
        "\n",
        "print('WIN through double')\n",
        "show_net(net, State().play('B2 A2 A3 C1'))\n",
        "\n",
        "# hard case: putting on A1 will cause double\n",
        "print('strategic WIN by following double')\n",
        "show_net(net, State().play('B1 A3'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w2LWyl8p6GK"
      },
      "outputs": [],
      "source": [
        "# Search with trained net\n",
        "\n",
        "tree = Tree(net)\n",
        "tree.think(State(), 100000, show=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "BotsForGames_Sprint2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
